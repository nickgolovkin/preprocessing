# Основные сведения о машинном обучении
Машинное обучение – это класс компьютерных алгоритмов, характерной
чертой которых является не прямое решение задачи, а обучение за счёт
применения решений множества сходных задач [10].
В классическом программировании, люди создают правила (программу) и
данные, которые должны быть обработаны в соответствии с этими правилами, а
затем получают ответы. При машинном обучении человек вводит данные, а
также ответы, соответствующие этим данным, и на выходе получает правила,
которые затем могут быть применены к новым данным для получения
соответствующих ответов (рисунок 6).

Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.

Machine learning (ML) is a field devoted to understanding and building methods that let machines "learn" – that is, methods that leverage data to improve computer performance on some set of tasks.[1]

Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, agriculture, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.[3][4] 

Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.[8][9]

In its application across business problems, machine learning is also referred to as predictive analytics. 

Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can sometimes be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". Other times, they can be more nuanced, such as "X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist".[10]

Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.[11]

The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid. This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits has often been used.

Система машинного обучения обучается, а не программируется. Ей
предъявляется множество примеров, относящихся к задаче, и она находит
статистическую структуру в этих примерах, что в конечном итоге позволяет
системе выработать правила для автоматизации задачи [10].
Процесс машинного обучения может быть разбит на следующие этапы
подготовки и создания модели:
− подготовка данных (устранение дублирования, предобработка);
− выбор модели и ее обучение;
− оценка качества модели;
− использование модели для классификации новых примеров.
Рассмотрим более подробно такой подраздел машинного обучения, как
искусственные нейронные сети.

Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior. Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.

The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL. This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.

# Введение в искуственные нейронные сети
Искусственные нейронные сети – это математические модели, созданные
по подобию биологических нейронных сетей. Они являются одним из методов
машинного обучения [15].
Нейронная сеть основана на коллекции соединенных узлов, называемых
искусственными нейронами. Каждое соединение, подобно синапсам в
биологическом мозге, может передавать сигнал другим нейронам. Нейрон,
получающий сигнал, обрабатывает его и может отправить другой сигнал
соединенным с ним нейронам. Под сигналом понимается вещественное число.
Значение на выходе каждого нейрона подсчитывается путем применения
нелинейной функции к сумме его входов. Нелинейная функция используется для
обеспечения более сложных взаимодействий. Соединения между нейронами
называются гранями. У нейронов и граней есть веса, которые изменяются в
процессе обучения. Веса увеличивают или уменьшают силу сигнала. Нейроны
собраны в слои. Разные слои могут выполнять различные преобразования к
значениям, поступающим на вход. Сигналы перемещаются от первого
(входного) слоя к последнему (выходному) слою. Ниже на рисунке 7 приведено
схематическое представление полносвязной сети – сети, в которой каждый
нейрон предыдущего слоя связан с каждым нейронном следующего.
Нейронные сети обучаются путем обработки примеров, состоящих из
входного значения и результата. Обучение нейронной сети обычно производится
определением разницы между значением на выходе нейронной сети
(предсказанием) и результатом из примера. Такая разница называется значением
потерь. После этого сеть изменяет свои веса таким образом, чтобы уменьшить
это значение. С каждой новой итерацией значение потерь становится все меньше
и меньше, и, достигнув определенного критерия (например, точность превысила
определенный порог), обучение нейронной сети приостанавливается [10].
При обучении нейронной сети выполняется прямой и обратный ход.
Прямой ход.
1. На входной слой нейронной сети подается тензор и распространяется
по всей сети от слоя к слою.
2. Вычисляется выход сети.
Обратный ход.
1. Вычисляется разность между желаемым выходом сети и фактическим.
В результате получается значение потерь.
2. Полученный сигнал распространяется в обратном направлении
соединений с нейронами, и впоследствии корректируются веса сети с
целью минимизации ошибки.
Так как нейронной сети нужно очень большое количество данных для
обучения, уместить которое все сразу бывает чаще всего невозможно в ОЗУ
компьютера или видеопамяти видеокарты, то используют обучение при помощи
батчей. Батч – это малая часть набора данных, которая подается на вход
нейронной сети.
Обучение с помощью батчей происходит следующим образом.
1. Весь набор данных делится на определенное количество батчей.
2. На вход нейронной сети поступает батч, происходит прямой и
обратный ход.
3. На вход нейронной сети поступает следующий батч, происходит
прямой и обратный ход и т.д., пока на вход не поступят все батчи.
Когда на вход нейронной сети поступили все батчи и для каждого из них
произошли прямой ход и обратный ход, то говорят, что прошла 1 эпоха.
В основе обучения нейронных сетей лежит применение стохастического
градиентного спуска.
Если функция дифференцируема, то теоретически возможно найти ее
минимум аналитически: известно, что минимум функции – это точка, где
производная равна 0, поэтому достаточно найти все точки, где производная
обращается в 0, и проверить, в какой из этих точек функция имеет наименьшее
значение. Применительно к нейронной сети это означает аналитическое
нахождение комбинации значений весов, которая дает наименьшее значение для
функции потерь [10]. Этого можно достичь, решив уравнение (2) для 𝑊𝑊.
∇(𝑓𝑓)(𝑊𝑊) = 0, (2)
где ∇(𝑓𝑓)(𝑊𝑊) – градиент функции 𝑓𝑓, 𝑓𝑓 – функция нейронной сети, 𝑊𝑊 –
весовые коэффициенты нейронной сети.
Это полиномиальное уравнение из 𝑁𝑁 переменных, где 𝑁𝑁 – количество
параметров в сети. Хотя такое уравнение можно решить для 𝑁𝑁 = 2 или 𝑁𝑁 = 3,
это трудновыполнимо для реальных нейронных сетей, где число параметров
никогда не бывает меньше нескольких тысяч и часто может составлять
несколько десятков миллионов [16]. Вместо этого можно использовать
следующий алгоритм, называемый стохастическим градиентным спуском:
1. Взять батч данных, состоящих из примеров для обучения 𝑥𝑥 и
соответствующих меток 𝑦𝑦.
2. Выполнить прямой ход на взятом батче и получить предсказания 𝑦𝑦𝑝𝑝𝑝𝑝𝑝𝑝𝑝𝑝 .
3. Вычислить значение потерь сети на данном батче между 𝑦𝑦𝑝𝑝𝑝𝑝𝑝𝑝𝑝𝑝 и 𝑦𝑦.
4. Вычислить градиент значения потерь относительно параметров сети
(обратный ход).
5. Немного изменить параметры в направлении, противоположному
направлению градиента.
Процесс классификации с помощью нейронной сети делится на 2 этапа:
обучение и использование. Вначале на вход нейронной сети подаются примеры
для обучения. Далее сеть обучается, изменяя и настраивая весовые
коэффициенты, и уже с готовыми преобразованными весами используется как
классификатор.
Основными "строительными блоками" нейронных сетей являются
следующие сущности:
− слой – объединенные в одну группу нейроны;
− функция активации – функция, определяющая выходной сигнал
нейрона, основываясь на входном сигнале или наборе входных
сигналов. например, softmax, sigmoid, relu;
− функция потерь (целевая функция) – функция, значение которой
необходимо минимизировать при обучении нейронной сети;
− оптимизатор – алгоритм, определяющий то, как нейронная сеть будет
обновлять свои веса, основываясь на функции потерь.
Число нейронов, количество слоев, используемые функции активации и
оптимизатор называются гиперпараметрами сети.
При обучении стараются подобрать гиперпараметры так, чтобы достичь
максимальной производительности (высокой точности, минимального значения
потерь и т.д.).
Одним из ключевых понятий при работе с нейронными сетями является
понятие тензоров. Тензоры – это обобщение матриц на произвольное число
измерений. Матрица – это двумерный тензор.
Основные типы тензоров в нейронных сетях:
− скаляры (0D тензоры). Тензор, содержащий только одно число,
называется скаляром;
29
− векторы (1D тензоры). Массив чисел называется вектором, или
одномерным тензором. Считается, что одномерный тензор имеет ровно
одну ось;
− матрицы (двумерные тензоры). Массив векторов называется матрицей,
или двумерным тензором. Матрица имеет две оси (часто называемые
строками и столбцами);
− 3D тензоры. Если поместить матрицы в новый массив, то получится 3D
тензор, который можно визуально интерпретировать как куб чисел.
Помещая трехмерные тензоры в массив, можно создать
четырехмерный тензор, и так далее. Ниже на рисунке 8 приведена
визуальная интерпретация 3D тензора.
Тензор определяется тремя ключевыми атрибутами:
− количество осей (ранг). Например, трехмерный тензор имеет три оси, а
матрица – две оси;
− форма – это кортеж целых чисел, который описывает, сколько
измерений имеет тензор по каждой оси. Например, матрица с 3
строками и 5 столбцами имеет форму (3,5);
− тип данных. Тип данных, содержащихся в тензоре; например, тип
тензора может быть float32, uint8, float64 и так далее. В редких случаях
можно встретить тензор char.
Все операции, производимые нейронной сетью, она производит над
тензорами
Рассмотрев общий принцип работы искусственных нейронных сетей,
перейдем к их разновидности, специально созданной для распознавания
изображений. 

# Предобработка текстового набора данных
В настоящее время для обработки текстов на естественном языке всё чаще применяются нейронные сети. Однако, чтобы получить более качественные результаты, текст, являющийся для них входными данными необходимо предобработать.

Текстовые данные для нейронной сети поступают в виде двумерного тензора (матрицы). 

Различные методы предобработки можно поделить на следующие группы:
- Простые методы предобработки
- Методы нормализации
- Методы векторизации
- Методы балансирования текстового набора данных.

Рассмотрим каждую группу методов подробнее.

## Простые методы предобработки
К простым методам предобработки относятся следующие методы:
- Удаление дубликатов
- Удаление стоп-слов
- Удаление символов пунктуации
- Удаление чисел
- Удаление ведущих и конечных пробелов
- Приведение слов к единому регистру

## Методы нормализации
**Что такое нормализация текста https://en.wikipedia.org/wiki/Text_normalization https://towardsdatascience.com/text-normalization-for-natural-language-processing-nlp-70a314bfa646**

Прежде чем применять к тексту методы нормализации, его необходимо токенизировать.
Токенизация - это ...
Токен - это ...
Например, ...

**Как производится токенизация**

### Стемминг
**Что такое стемминг?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### Лемматизация
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

## Методы векторизации
Нейронные сети оперируют числами, поэтому, прежде чем подать текст на вход, его необходимо векторизовать.

**Что такое векторизация?**
**Подробнее, зачем нужна векторизация**

К основным методам векторизации относятся:
- Мешок слов
- Индексы (? не помню, как правильно, надо посмотреть)
- TF-IDF
- Embedding

### Мешок слов
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### Индексы
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### TF-IDF
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### Embedding
Тут два каких то метода
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

## Методы балансирования текстового набора данных
**Зачем нужно (взять из прошлого диплома)**

### Даунсемплинг
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### Оверсемплинг
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

### Приведение количества примеров к среднему значению
**Что такое?**
**Как производится?**
**Пример**
**Плюсы и минусы**

# Архитектуры нейронных сетей для классификации текста
## RNN
**Что такое?**
**Каков принцип работы?**
**Картинки**
**Плюсы и минусы**

## LSTM
**Что такое?**
**Каков принцип работы?**
**Картинки**
**Плюсы и минусы**

# Решение задачи классификации
**Постановка задачи классификации**
**Оценка качествая обучения модели для решения задачи классификации - Точность и еще какие-то метрики**




