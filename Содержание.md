Разработка программного
обеспечения для исследования
влияния предобработки текста на
точность решения задач
классификации текстовой
информации - по сути это тема как у Оли, просто переформулированная, если вчитаться. Скорее всего нужно просто добавить вывод графиков в модуль обучения. Получается та же тема, только с уклоном на предобработку.

Можно написать потом что-то типа "для применения полученных моделей... модуль эксплуатации". Т.е. связать одно с другим. Можно еще сделать "поиск" лучшего решения предобработки. - 2 режима - с поиском и без. Т.е. удалили числа, записали результат и т.д.

У Оли
Разработка программного обеспечения классификации текстовой информации с использованием интеллектуальных методов обработки

https://towardsdatascience.com/nlp-learning-series-part-1-text-preprocessing-methods-for-deep-learning-20085601684b
https://www.google.ru/books/edition/Artificial_Intelligence_for_Big_Data/pF9dDwAAQBAJ?hl=ru&gbpv=1&dq=text+preprocessing+remove+stopwords&pg=PA165&printsec=frontcover

Подготовить ответ на вопрос: "А почему Python?", "А почему Keras?", "А в чем практическая ценность вашей работы?", "А где все это можно применить?", "Как производится стемминг, лемматизация, токенизация?", "ЧТо такое Embedding и как он производится?", "Что такое RNN, LSTM, в чем разница, преимущества?", "Зачем нужна предобработка текста?"

- ВВЕДЕНИЕ
- Постановка задачи
- Технико-экономическое обоснование
- Обоснование выбора средств разработки
- Теоретическая часть
    - Основные сведения о машинном обучении
    - Введение в искуственные нейронные сети
    - Предобработка текстового набора данных
        - Простые методы предобработки (найти термин получше?)
            - Удаление дубликатов
            - Удаление стоп-слов
            - Удаление символов пунктуации
            - Удаление чисел
            - Удаление ведущих и конечных пробелов
            - Приведение слов к единому регистру
            - Результаты
        - Методы нормализации (в каждом описать плюсы и минусы)
            - (про токенизацию написать здесь, но вскользь, типо это один из необходимых шагов, а дальше нужно нормализовать)
            - Стемминг
            - Лемматизация
            - Результаты
        - Методы векторизации (в каждом описать плюсы и минусы)
            - Мешок слов
            - Индексы
            - TF-IDF
            - Embedding (?)
                - (там два разных способа было, ты в одной из работ писал)
            - Результаты
        - Методы балансирования текстового набора данных (в каждом описать плюсы и минусы)
            - (кратко описать, что будет, если набор несбалансированный)
            - К меньшему (Даунсемплинг)
            - К большему (Оверсемплинг)
            - К среднему
            - Результаты
    - Архитектуры нейронных сетей для классификации текста
        - RNN
        - LSTM
    - Решение задачи классификации
        - Оценка качества обучения модели для решения задачи классификации
            - Точность
            - еще какие-то метрики
- Практическая часть
    - Проектирование функциональности программного обеспечения
    - Разработка архитектуры программного обеспечения (здесь будут диаграммы развертывания и т.д.)
    - Разработка модуля предобработки текстового набора данных
    - Разработка модуля модели (это не надо писать, просто общий класс)
    - Разработка модуля обучения
    - Разработка модуля эксплуатации
        - Разработка веб-приложения (это просто для тебя напоминание, что будет веб-приложение)
            - Разработка алгоритмов
            - Разработка классов
            - Программная реализация
            - Разработка пользовательского интерфейса
- Программная документация
    - Описание применения
        - Назначение программы
        - Условия применения
        - Описание задачи
        - Входные и выходные данные
    - Руководство оператора
        - Назначение программы
        - Условия выполнения программы
        - Выполнение программы
        - Сообщения оператору
    - Руководство оператора
        - Назначение и условия применения программы
        - Обращения к программе
        - Входные и выходные данные
        - Сообщения
    - Руководство программиста
        - Общие сведения о программе
        - Структура программы
        - Настройка программы
        - Проверка программы
        - Сообщения системному программисту
- Тестирование
    - Модуль предобработки данных (ВОТ ЗДЕСЬ ИЛИ НИЖЕ ОПИСАТЬ РЕЗУЛЬТАТЫ ТЕСТИРОВАНИЯ, насколько какой метод предобработки был лучше)
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
    - Модуль обучения
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
    - Модуль эксплуатации
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
- Заключение
- Список использованных источников
- Приложение А. Листинг наиболее значимых частей программы

Придумать примеры, для чего может использоваться классификация текста (отзывы на банки.ру - причины негативных отзывов и т.д.)

Архитектура
Модуль предобработки, модуль обучения, модуль эксплуатации

Еще файлик commons.py, в котором содержатся DTO модели для сериализации и т.д. Модуль предобработки туда тоже подключен?

Модуль предобработки представляет из себя файл preprocessing_module.py, содержащий класс Preprocessor. У него есть список предобработок, которые необходимо выполнить. При запуске он их выполняет.

Модуль предобработки подключен в модуль обучения и модуль эксплуатации

Модуль обучения представляет из себя .ipynb файл и располагается в Google Colab. Прописать конвенции по путям.

В отчете можно взять, что должно быть.

В методе для предобработки df, столбец с текстом, столбец с классом

Вкратце - данные загружаются, высвечивается таблица с распределением классов, данные предобрабатываются с помощью модуля предобработки, разделяются на тренировочный и тестовый наборы (это в константах?), после чего происходит обучение модели и вывод результатов обучения - на валидационной выборке и тестовой выборке. Выводятся метрики + графики + матрица ошибок? EarlyStopping и сохранение лучшей. После всего этого модель, препроцессор и токенайзер сохраняются в отдельый файл (класс с моделью). 

В модуле эксплуатации подгружается файл с моделью, файл с новым набором данных, он предобрабатывается и используется модель для предсказаний. Результаты сохраняются в файл в виде Текст, Класс, Точность. Выводится такая же таблица. Модуль эксплуатации - веб-приложение. На вход поступает csv файл, после чего отрабатывает модель и выдает таблицу. Можно загрузить как один пример, так и несколько. Придумать конвенции куда класть модель и т.д. 

Если один, то отображается сам фрагмент и класс, точность
Если файл, то отображается таблица + кнопка "Скачать", позволяющая скачать таблицу.

Preprocessor .addPreprocessing(TokenizationMode) и т.д., все складывается в нужные поля. Взаимоисключающие исключаются - используется последнее введенное значение. По умолчанию если не задан метод нормализации, то выполняется просто токенизация. А если не задан метод векторизации, то применяется мешок слов

SimpleTextPreprocessingMechanism(SimpleTextPreprocessing.DELETE_NUMBERS)
SimpleDatasetPreprocessingMechanism(SimpleDatasetPreprocessing.DELETE_DUPLICATES)
WordNormalizationMechanism(WordNormalizationMode.LEMMATIZATION)
SequenceVectorizationMechanism(SequenceVectorizationMode.BAG_OF_WORDS)
ClassBalancingMechanism(ClassBalacingMode.UPSAMPLING)

Если в метод обучения был передан embedding, то добавляем слой embedding замороженный https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras

Нужно кэшировать лемматизацию, стемминг при поиске лучших предобработок

Vectorization возвращает токенизатор для дальнейшего применения? Или это препроцессор в себе сохраняет токенайзер? И WordNormalizationMechanism на вход словарь принимает или токенизатор. Хотя наверное словарь? Наверное словарь надо возвращать

https://stackoverflow.com/questions/49476043/using-keras-tokenizer-with-premade-indexed-dictionary

Значит методы нужны fit - чтобы создать словарь... хотя это же токенайзер делает, получается словарь всегда будет, . isTrained, весы/словарь сохраняем в самом механизме, он потом засериализуется

Сначала fit, потом векторизировать. попробовать сначала каждый метод отдельно с df прогнать, а только потом уже обобщать. Потом сделать метод preprocess_dataset. Потом сделать модуль обучения, потом сделать модуль эксплуатации

preprocess_dataset_for_training
preprocess_dataset_for_evaluating

https://www.depends-on-the-definition.com/guide-to-word-vectors-with-gensim-and-keras/ - как использовать эмбеддинги
https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras - нужно выходной словарь генсима скормить токенайзеру - последний ответ близок к правде

Подсовываешь к токенайзеру словарь от генсима, а в керас - матрицу по словарю

gensim возвращает словарь + матрицу весов (эмбеддинги)
токенайзер только словарь

проброс output_params. Если есть в output_params препроцессора, то делаем слой эмбеддинга

На вход подается все сразу, если не обучен, то обучается.
Получается так - механизмы возвращают токенайзеры, 
Потом с помощью токенайзеров векторизируем последовательности и добавляем их к df в виде preproccessed_text
методы у механизма is_fitted, fit, process. process выбрасывает исключение, если is_fitted = false.

Порядок такой
SimpleDatasetPreprocessingMechanism(SimpleDatasetPreprocessing.DELETE_DUPLICATES)
SimpleTextPreprocessingMechanism(SimpleTextPreprocessing.DELETE_NUMBERS)
WordNormalizationMechanism(WordNormalizationMode.LEMMATIZATION)
SequenceVectorizationMechanism(SequenceVectorizationMode.BAG_OF_WORDS)
ClassBalancingMechanism(ClassBalacingMode.UPSAMPLING)

В механизме нормализации кэш, будет метод reset, который его сбрасывает, перед сохранением в единый файл - сбрасываем. Нужен для более быстрого поиска наилучшей предобработки


- вывести количество примеров +
- вывести количество примеров в каждом классе +
- вывести количество примеров в каждом классе после предобработки +
- вывести использованные предобработки в виде текста
- вывести метрики при обучении
- вывести тестовые метрики
- вывести матрицу ошибок
- сохранить все в TrainedModel

"Использованные методы предобработки текстовых данных
Простые методы предобработки текста: ...
Простые методы предобработки набора данных: ...
Метод нормализации слов: ...
Метод векторизации: ...
Метод балансирования набора данных: ..."

https://en.wikipedia.org/wiki/Sensitivity_and_specificity
https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/ - графики
https://medium.com/mlearning-ai/confusion-matrix-for-multiclass-classification-f25ed7173e66
https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/

Если ошибка валидации, то на странице с загрузкой будет появляться алерт - фронт + бэк

"Что-то пошло не так..."
Стектрейс

Cамому накидать различные варианты предобработки (захардкодить), прогнать и выбрать лучший

Простые методы по одному, потом со всеми + нормализацияи т д

Тестирование:
Сначала просто по каждому простому методу предобработки + CBOW + avg (avg должен быть один и тот же каждый раз, как и набор данных)
Потом все простые + методы нормализации + CBOW + avg
Потом все простые + методы нормализации + методы векторизации + avg

Посмотреть про оценку качества обучения (она гвоорит, что нужно писать оценка качества полученных моделей - на тестовой выборке)

Или все таки более атомарно, а потом с каждым лучшим методом?

# Проверка
- [X] Введение
    - Ок
- [X] Постановка задачи
    - Ок
- [X] Технико-экономическое обоснование
    - Ок
- [X] Обоснование выбора средств разработки
    - Ок
- [X] Теоретическая часть
    - [X] Основные сведения о машинном обучении
        - Ок
    - [X] Введение в искусственные нейронные сети
        - Ок
    - [X] Предобработка текстового набора данных
        - [X] Простые методы предобработки
            - Ок
        - [X] Методы нормализации
            - Ок
        - [X] Методы векторизации
            - Ок
        - [X] Методы балансирования
            - Ок
    - [] Виды нейронных сетей для классификации текста (ей сошло)
    - [X] Решение задачи классификации
        - Ок
    - [X] Оценка качества обучения
        - Ок
- [] Практическая часть
    - [X] Проектирование функциональности программного обеспечения
        - Ок
    - [X] Разработка архитектуры программного обеспечения
        - Ок
    - [X] Разработка модуля предобработки текстового набора данных
        - [X] 5.3.2 Разработка алгоритмов
            - [X] Добавить блок-схему
        - [X] 5.3.3 Программная реализация
            - Ок
    - [X] Разработка приложения для обучения моделей
        - [X] 5.4.2 Разработка алгоритмов
            - Добавить блок-схему
    - [X] Разработка веб-приложения
        - [X] 5.5.1 Разработка алгоритма
            - Добавить блок-схему
        - [X] 5.5.2 Разработка классов
            - Добавить классы
        - [X] 5.5.4 Разработка пользовательского интерфейса 
            - Добавить страницу об ошибке
- [] Программная документация
    - [X] Описание применения
    - [] Руководство оператора
    - [] Руководство программиста
    - [] Руководство системного программиста
- [] Тестирование
    - [] Исследование влияния предобработки текста на точность классификации текстовых данных
    - [] Приложение для обучения моделей
    - [] Веб-приложение

Заменить кавычки на елочки, заменить дефис на тире



        1
        2
        3


Научная новизна - исследования влияния различных методов предобработки текстовых данных на русском языке на точность классификации текстовых данных при помощи нейронных сетей

Наверное не стоит писать в инструкции про 3 части, потому что модуль - это составная часть других приложений, а не отдельное. В других местах писать можешь, т к там про разработку


1. Предобработать набор данных, используя добавленные механизмы простой предобработки текстового набора данных
2. Предобработать текстовые данные, используя механизмы простой предобработки текстовых данных
3. Если добавлен механизм нормализации слов
    Произвести нормализацию слов в текстовых данных
4. Создать токенайзер со словарем, используя имеющиеся текстовые данные
5. Произвести векторизацию текстовых данных
6. Добавить векторизованные текстовые данные к набору данных в виде столбца "preprocessed_texts"
7. Если добавлен механизм балансирования набора данных
    Произвести балансирование набора данных

Для i от 0 до количества добавленных простых методов предобработки набора данных
Предобработать набор данных, используя i метод

Для i от 0 до количества добавленных простых методов предобработки текстовых данных
Предобработать текстовые данные, используя i метод

Загрузить набор данных
Отобразить общее количество примеров
Отобразить количество примеров в каждом классе
Создать препроцессор
Разбить набор данных на обучающую и тестовую выборки
Предобработать обучающую выборку
Отобразить количество примеров в каждом классе после предобработки
Скомпилировать модель
Обучить модель на обучающей выборке
Оценить качество полученной модели на тестовой выборке

На вход поступил корректный текст?
Предобработать загруженный текст
Использовать модель для получения предсказания
Отобразить полученный результат работы модели

На вход поступил корректный CSV-файл?
Для i от 0 до количества вхождений в CSV-файле
Предобработать загруженный текст
Использовать модель для получения предсказаний
Отобразить полученные результаты работы модели

# Исследование влияния предобработки текста на точность классификации текстовых данных
**про набор данных** **столбчатые диаграммы с распределением классов**

**Как проводилось исследование - то, что набор данных зафиксировали, какие архитектуры нейронных сетей - прям код**

# Простые методы предобработки текста
class SimpleTextPreprocessing(Enum):
  # Удаление символов пунктуации
  DELETE_PUNCTUATION = 1
  # Удаление чисел
  DELETE_NUMBERS = 2
  # Удаление излишних пробельных символов
  DELETE_EXTRA_WHITESPACES = 3
  # Приведение слов к нижнему буквенному регистру
  TO_LOWER_CASE = 4
  # Удаление стоп-слов
  DELETE_STOPWORDS = 5

# Простые методы предобработки набора данных
class SimpleDatasetPreprocessing(Enum):
  # Удаление дубликатов
  DELETE_DUPLICATES = 1

# Методы нормализации
class WordNormalizationMode(Enum):
  # Стемминг
  STEMMING = 1
  # Лемматизация
  LEMMATIZATION = 2

# Методы векторизации
class SequenceVectorizationMode(Enum):
  # Мешок слов
  BAG_OF_WORDS = 1
  # TF-IDF
  TF_IDF = 2
  # Word2Vec CBOW
  WORD2VEC_CBOW = 3
  # Word2Vec Skip gram
  WORD2VEC_SKIP_GRAM = 4

# Методы балансирования текстового набора данных
class DatasetBalancingMode(Enum):
  # Даунсемплинг
  DOWNSAMPLING = 1
  # Апсемплинг
  UPSAMPLING = 2
  # Приведение количества примеров в каждом классе к среднему значению
  AVERAGING = 3


Простые методы предобработки    Простые методы предобработки набора данных  Метод нормализаци   
-

Наверное лучше отдельно рассмотреть влияние каждой группы методов