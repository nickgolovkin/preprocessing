Разработка программного
обеспечения для исследования
влияния предобработки текста на
точность решения задач
классификации текстовой
информации - по сути это тема как у Оли, просто переформулированная, если вчитаться. Скорее всего нужно просто добавить вывод графиков в модуль обучения. Получается та же тема, только с уклоном на предобработку.

Можно написать потом что-то типа "для применения полученных моделей... модуль эксплуатации". Т.е. связать одно с другим. Можно еще сделать "поиск" лучшего решения предобработки. - 2 режима - с поиском и без. Т.е. удалили числа, записали результат и т.д.

У Оли
Разработка программного обеспечения классификации текстовой информации с использованием интеллектуальных методов обработки

https://towardsdatascience.com/nlp-learning-series-part-1-text-preprocessing-methods-for-deep-learning-20085601684b
https://www.google.ru/books/edition/Artificial_Intelligence_for_Big_Data/pF9dDwAAQBAJ?hl=ru&gbpv=1&dq=text+preprocessing+remove+stopwords&pg=PA165&printsec=frontcover

Подготовить ответ на вопрос: "А почему Python?", "А почему Keras?", "А в чем практическая ценность вашей работы?", "А где все это можно применить?", "Как производится стемминг, лемматизация, токенизация?", "ЧТо такое Embedding и как он производится?", "Что такое RNN, LSTM, в чем разница, преимущества?", "Зачем нужна предобработка текста?"

- ВВЕДЕНИЕ
- Постановка задачи
- Технико-экономическое обоснование
- Обоснование выбора средств разработки
- Теоретическая часть
    - Основные сведения о машинном обучении
    - Введение в искуственные нейронные сети
    - Предобработка текстового набора данных
        - Простые методы предобработки (найти термин получше?)
            - Удаление дубликатов
            - Удаление стоп-слов
            - Удаление символов пунктуации
            - Удаление чисел
            - Удаление ведущих и конечных пробелов
            - Приведение слов к единому регистру
            - Результаты
        - Методы нормализации (в каждом описать плюсы и минусы)
            - (про токенизацию написать здесь, но вскользь, типо это один из необходимых шагов, а дальше нужно нормализовать)
            - Стемминг
            - Лемматизация
            - Результаты
        - Методы векторизации (в каждом описать плюсы и минусы)
            - Мешок слов
            - Индексы
            - TF-IDF
            - Embedding (?)
                - (там два разных способа было, ты в одной из работ писал)
            - Результаты
        - Методы балансирования текстового набора данных (в каждом описать плюсы и минусы)
            - (кратко описать, что будет, если набор несбалансированный)
            - К меньшему (Даунсемплинг)
            - К большему (Оверсемплинг)
            - К среднему
            - Результаты
    - Архитектуры нейронных сетей для классификации текста
        - RNN
        - LSTM
    - Решение задачи классификации
        - Оценка качества обучения модели для решения задачи классификации
            - Точность
            - еще какие-то метрики
- Практическая часть
    - Проектирование функциональности программного обеспечения
    - Разработка архитектуры программного обеспечения (здесь будут диаграммы развертывания и т.д.)
    - Разработка модуля предобработки текстового набора данных
    - Разработка модуля модели (это не надо писать, просто общий класс)
    - Разработка модуля обучения
    - Разработка модуля эксплуатации
        - Разработка веб-приложения (это просто для тебя напоминание, что будет веб-приложение)
            - Разработка алгоритмов
            - Разработка классов
            - Программная реализация
            - Разработка пользовательского интерфейса
- Программная документация
    - Описание применения
        - Назначение программы
        - Условия применения
        - Описание задачи
        - Входные и выходные данные
    - Руководство оператора
        - Назначение программы
        - Условия выполнения программы
        - Выполнение программы
        - Сообщения оператору
    - Руководство оператора
        - Назначение и условия применения программы
        - Обращения к программе
        - Входные и выходные данные
        - Сообщения
    - Руководство программиста
        - Общие сведения о программе
        - Структура программы
        - Настройка программы
        - Проверка программы
        - Сообщения системному программисту
- Тестирование
    - Модуль предобработки данных (ВОТ ЗДЕСЬ ИЛИ НИЖЕ ОПИСАТЬ РЕЗУЛЬТАТЫ ТЕСТИРОВАНИЯ, насколько какой метод предобработки был лучше)
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
    - Модуль обучения
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
    - Модуль эксплуатации
        - План тестирования
        - Результаты тестирования
        - Анализ результатов тестирования
- Заключение
- Список использованных источников
- Приложение А. Листинг наиболее значимых частей программы

Придумать примеры, для чего может использоваться классификация текста (отзывы на банки.ру - причины негативных отзывов и т.д.)

Архитектура
Модуль предобработки, модуль обучения, модуль эксплуатации

Еще файлик commons.py, в котором содержатся DTO модели для сериализации и т.д. Модуль предобработки туда тоже подключен?

Модуль предобработки представляет из себя файл preprocessing_module.py, содержащий класс Preprocessor. У него есть список предобработок, которые необходимо выполнить. При запуске он их выполняет.

Модуль предобработки подключен в модуль обучения и модуль эксплуатации

Модуль обучения представляет из себя .ipynb файл и располагается в Google Colab. Прописать конвенции по путям.

В отчете можно взять, что должно быть.

В методе для предобработки df, столбец с текстом, столбец с классом

Вкратце - данные загружаются, высвечивается таблица с распределением классов, данные предобрабатываются с помощью модуля предобработки, разделяются на тренировочный и тестовый наборы (это в константах?), после чего происходит обучение модели и вывод результатов обучения - на валидационной выборке и тестовой выборке. Выводятся метрики + графики + матрица ошибок? EarlyStopping и сохранение лучшей. После всего этого модель, препроцессор и токенайзер сохраняются в отдельый файл (класс с моделью). 

В модуле эксплуатации подгружается файл с моделью, файл с новым набором данных, он предобрабатывается и используется модель для предсказаний. Результаты сохраняются в файл в виде Текст, Класс, Точность. Выводится такая же таблица. Модуль эксплуатации - веб-приложение. На вход поступает csv файл, после чего отрабатывает модель и выдает таблицу. Можно загрузить как один пример, так и несколько. Придумать конвенции куда класть модель и т.д. 

Если один, то отображается сам фрагмент и класс, точность
Если файл, то отображается таблица + кнопка "Скачать", позволяющая скачать таблицу.

Preprocessor .addPreprocessing(TokenizationMode) и т.д., все складывается в нужные поля. Взаимоисключающие исключаются - используется последнее введенное значение. По умолчанию если не задан метод нормализации, то выполняется просто токенизация. А если не задан метод векторизации, то применяется мешок слов

SimpleTextPreprocessingMechanism(SimpleTextPreprocessing.DELETE_NUMBERS)
SimpleDatasetPreprocessingMechanism(SimpleDatasetPreprocessing.DELETE_DUPLICATES)
WordNormalizationMechanism(WordNormalizationMode.LEMMATIZATION)
SequenceVectorizationMechanism(SequenceVectorizationMode.BAG_OF_WORDS)
ClassBalancingMechanism(ClassBalacingMode.UPSAMPLING)

Если в метод обучения был передан embedding, то добавляем слой embedding замороженный https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras

Нужно кэшировать лемматизацию, стемминг при поиске лучших предобработок

Vectorization возвращает токенизатор для дальнейшего применения? Или это препроцессор в себе сохраняет токенайзер? И WordNormalizationMechanism на вход словарь принимает или токенизатор. Хотя наверное словарь? Наверное словарь надо возвращать

https://stackoverflow.com/questions/49476043/using-keras-tokenizer-with-premade-indexed-dictionary

Значит методы нужны fit - чтобы создать словарь... хотя это же токенайзер делает, получается словарь всегда будет, . isTrained, весы/словарь сохраняем в самом механизме, он потом засериализуется

Сначала fit, потом векторизировать. попробовать сначала каждый метод отдельно с df прогнать, а только потом уже обобщать. Потом сделать метод preprocess_dataset. Потом сделать модуль обучения, потом сделать модуль эксплуатации

preprocess_dataset_for_training
preprocess_dataset_for_evaluating

https://www.depends-on-the-definition.com/guide-to-word-vectors-with-gensim-and-keras/ - как использовать эмбеддинги
https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras - нужно выходной словарь генсима скормить токенайзеру - последний ответ близок к правде

Подсовываешь к токенайзеру словарь от генсима, а в керас - матрицу по словарю

gensim возвращает словарь + матрицу весов (эмбеддинги)
токенайзер только словарь

проброс output_params. Если есть в output_params препроцессора, то делаем слой эмбеддинга

На вход подается все сразу, если не обучен, то обучается.
Получается так - механизмы возвращают токенайзеры, 
Потом с помощью токенайзеров векторизируем последовательности и добавляем их к df в виде preproccessed_text
методы у механизма is_fitted, fit, process. process выбрасывает исключение, если is_fitted = false.

Порядок такой
SimpleDatasetPreprocessingMechanism(SimpleDatasetPreprocessing.DELETE_DUPLICATES)
SimpleTextPreprocessingMechanism(SimpleTextPreprocessing.DELETE_NUMBERS)
WordNormalizationMechanism(WordNormalizationMode.LEMMATIZATION)
SequenceVectorizationMechanism(SequenceVectorizationMode.BAG_OF_WORDS)
ClassBalancingMechanism(ClassBalacingMode.UPSAMPLING)

В механизме нормализации кэш, будет метод reset, который его сбрасывает, перед сохранением в единый файл - сбрасываем. Нужен для более быстрого поиска наилучшей предобработки


- вывести количество примеров +
- вывести количество примеров в каждом классе +
- вывести количество примеров в каждом классе после предобработки +
- вывести использованные предобработки в виде текста
- вывести метрики при обучении
- вывести тестовые метрики
- вывести матрицу ошибок
- сохранить все в TrainedModel

"Использованные методы предобработки текстовых данных
Простые методы предобработки текста: ...
Простые методы предобработки набора данных: ...
Метод нормализации слов: ...
Метод векторизации: ...
Метод балансирования набора данных: ..."

https://en.wikipedia.org/wiki/Sensitivity_and_specificity
https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/ - графики
https://medium.com/mlearning-ai/confusion-matrix-for-multiclass-classification-f25ed7173e66
https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/

Если ошибка валидации, то на странице с загрузкой будет появляться алерт - фронт + бэк

"Что-то пошло не так..."
Стектрейс

Cамому накидать различные варианты предобработки (захардкодить), прогнать и выбрать лучший

Простые методы по одному, потом со всеми + нормализацияи т д

Тестирование:
Сначала просто по каждому простому методу предобработки + CBOW + avg (avg должен быть один и тот же каждый раз, как и набор данных)
Потом все простые + методы нормализации + CBOW + avg
Потом все простые + методы нормализации + методы векторизации + avg

Посмотреть про оценку качества обучения (она гвоорит, что нужно писать оценка качества полученных моделей - на тестовой выборке)

Или все таки более атомарно, а потом с каждым лучшим методом?

# Проверка
- [X] Введение
    - Ок
- [X] Постановка задачи
    - Ок
- [X] Технико-экономическое обоснование
    - Ок
- [X] Обоснование выбора средств разработки
    - Ок
- [] Теоретическая часть
    - [X] Основные сведения о машинном обучении
        - Ок
    - [X] Введение в искусственные нейронные сети
        - Ок
    - [X] Предобработка текстового набора данных
        - [X] Простые методы предобработки
            - Ок
        - [X] Методы нормализации
            - Ок
        - [X] Методы векторизации
            - Ок
        - [X] Методы балансирования
            - Ок
    - [] Виды нейронных сетей для классификации текста
    - [X] Решение задачи классификации
        - Ок
    - [X] Оценка качества обучения
        - Ок
- [] Практическая часть
    - [X] Проектирование функциональности программного обеспечения
        - Ок
    - [X] Разработка архитектуры программного обеспечения
        - Ок
    - [] Разработка модуля предобработки текстового набора данных
    - [] Разработка приложения для обучения моделей
    - [] Разработка веб-приложения
- [] Программная документация
    - [X] Описание применения
    - [] Руководство оператора
    - [] Руководство программиста
    - [] Руководство системного программиста

Заменить кавычки на елочки, заменить дефис на тире



        1
        2
        3


Научная новизна - исследования влияния различных методов предобработки текстовых данных на русском языке на точность классификации текстовых данных при помощи нейронных сетей

Наверное не стоит писать в инструкции про 3 части, потому что модуль - это составная часть других приложений, а не отдельное. В других местах писать можешь, т к там про разработку